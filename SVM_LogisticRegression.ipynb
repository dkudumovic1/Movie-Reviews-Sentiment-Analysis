{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries and helper functions"
      ],
      "metadata": {
        "id": "zMC8kVG4X_Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive\")"
      ],
      "metadata": {
        "id": "QYwuT0PCO-r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "id": "OnHoJRMmXk_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "0VQtj5lQW2AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "import json\n",
        "from sklearn import metrics as m\n",
        "import numpy as np\n",
        "from os import path\n",
        "import utils\n",
        "from utils import preprocessing\n",
        "from utils import feature_extraction\n",
        "from sklearn.calibration import CalibratedClassifierCV"
      ],
      "metadata": {
        "id": "W93J1WFtUlni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_files():\n",
        "  x_train = pd.read_csv('/content/drive/My Drive/nlp/data/x_train_without_preprocessing.csv', converters = {'review': str})\n",
        "  x_test = pd.read_csv('/content/drive/My Drive/nlp/data/x_test_without_preprocessing.csv', converters = {'review': str})\n",
        "  y_train = pd.read_csv('/content/drive/My Drive/nlp/data/y_train_without_preprocessing.csv').values.ravel()\n",
        "  y_test = pd.read_csv('/content/drive/My Drive/nlp/data/y_test_without_preprocessing.csv').values.ravel()\n",
        "\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "metadata": {
        "id": "lYT2IDP8U4ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def json_metrics(file_name, prediction_model, embedding, metrics, df):\n",
        "    dictionary = {'Model': prediction_model,\n",
        "                  'User embedding': embedding,\n",
        "                  'Metrics': metrics,\n",
        "                  'Data': df.to_dict('records')}\n",
        "\n",
        "    if path.isfile(file_name):  # file exist\n",
        "        with open(file_name) as fp:\n",
        "            listObj = json.load(fp)\n",
        "\n",
        "        listObj.append(dictionary)\n",
        "\n",
        "        with open(file_name, 'w') as json_file:\n",
        "            json.dump(listObj, json_file, indent=4)\n",
        "    else:\n",
        "        with open(file_name, 'w') as json_file:\n",
        "            json.dump([dictionary], json_file, indent=4)\n",
        "\n",
        "\n",
        "def metrics(y_test, y_pred, target_names):\n",
        "    tn, fp, fn, tp = m.confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
        "    dict_confusion = {'True negative': int(tn),\n",
        "                      'False positive': int(fp),\n",
        "                      'False negative': int(fn),\n",
        "                      'True positive': int(tp),\n",
        "                      }\n",
        "    dict_report = m.classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
        "    return {**dict_confusion, **dict_report}\n",
        "\n",
        "def metrics_for_neutral(y_test, y_pred, target_names):\n",
        "  FP = TP = TN = FN = NP = NN = 0\n",
        "\n",
        "  for i in range(len(y_pred)):\n",
        "    prediction = y_pred[i]\n",
        "    true = y_test[i]\n",
        "\n",
        "    if prediction == 1 and (true == 1 or true == 0):\n",
        "      FP += 1\n",
        "    elif prediction == 1 and (true == 3 or true == 4):\n",
        "      TP += 1\n",
        "    elif prediction == 0 and (true == 1 or true == 0) :\n",
        "      TN += 1\n",
        "    elif prediction == 0 and (true == 3 or true == 4):\n",
        "      FN += 1\n",
        "    elif prediction == 1 and true == 2:\n",
        "      NP += 1\n",
        "    elif prediction == 0 and true == 2:\n",
        "      NN += 1\n",
        "      \n",
        "  dict_confusion = {'True negative' : int(TN),\n",
        "        'False positive' : int(FP),\n",
        "        'False negative' : int(FN),\n",
        "        'True positive' : int(TP),\n",
        "        'Neutral positive' : int(NP),\n",
        "        'Neutral negative' : int(NN),\n",
        "        }\n",
        "  return {**dict_confusion}"
      ],
      "metadata": {
        "id": "IDuJZ1EvNMsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic regression"
      ],
      "metadata": {
        "id": "cq6620aCO_qU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tuning"
      ],
      "metadata": {
        "id": "y8ErXtTnU6w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "logModel = LogisticRegression()\n",
        "param_grid = [    \n",
        "    {'penalty' : ['l1', 'l2'],\n",
        "    'C' : np.logspace(-4, 4, 20),\n",
        "     'solver' : ['lbfgs', 'newton-cg', 'liblinear'],\n",
        "    'max_iter' : [500, 1000]\n",
        "    }\n",
        "]\n",
        "clf = GridSearchCV(logModel, param_grid = param_grid, cv=3, verbose=True)\n",
        "best_clf = clf.fit(x_train, y_train)\n",
        "best_clf.best_estimator_"
      ],
      "metadata": {
        "id": "5JNoeDpcU74u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The best accuracy score for the training dataset is {best_clf.best_score_:.4f}')\n",
        "print(f'The best hyperparameters are {best_clf.best_params_}')\n",
        "print(f'The accuracy score for the testing dataset is {best_clf.score(x_test, y_test):.4f}')\n",
        "print(best_clf.best_estimator_.get_params())"
      ],
      "metadata": {
        "id": "G-j3rguPVMGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Best model"
      ],
      "metadata": {
        "id": "vKqZf92oU9e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "#_, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "#COUNT VECTORIZER\n",
        "_, x_train, x_test = feature_extraction.get_count_vector(x_train['review'], x_test['review'], ngram_range=(1,2), min_df=0.0, remove_stopwords=False)\n",
        "\n",
        "model = LogisticRegression(C=29.763514416313132, penalty='l2', max_iter=500)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "\n",
        "predict = model.predict(x_test)\n",
        "probab = model.predict_proba(x_test)\n",
        "\n",
        "print(metrics(y_test, predict, ['Positive', 'Negative']))\n",
        "\n",
        "df= pd.DataFrame({'Id': np.arange(y_test.shape[0]), 'Label': y_test, 'Prediction': predict, 'Probability': probab.tolist()})\n",
        "df.to_csv('/content/drive/My Drive/nlp/probab/lr_cv_without_preprocessing.csv')"
      ],
      "metadata": {
        "id": "bxheClsAQEyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word2vec"
      ],
      "metadata": {
        "id": "ggFJAgWOVAQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#WORD2VEC\n",
        "word2vec_model = feature_extraction.create_word2vec_model(x_train['review'], x_test['review']) \n",
        "x_train, x_test = feature_extraction.get_word2vec_embedding(word2vec_model, x_train['review'], x_test['review']) \n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "3cVlUA4QiUxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GloVe"
      ],
      "metadata": {
        "id": "Osoet2yIq7fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#GLOVE\n",
        "dirname = os.path.dirname(__file__)\n",
        "filepath = os.path.join(dirname, 'glove.6B.200d.txt')\n",
        "\n",
        "word2vec_output_file = 'glove.6B.200d' + '.word2vec'\n",
        "\n",
        "glove_model = feature_extraction.load_glove_model(filepath, word2vec_output_file)\n",
        "x_train, x_test = feature_extraction.get_glove_embedding(glove_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "UfvRyqpUq6eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM"
      ],
      "metadata": {
        "id": "nAKaLlw_UXjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "#dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "#COUNT VECTORIZER\n",
        "_, x_train, x_test = feature_extraction.get_count_vector(x_train['review'], x_test['review'], ngram_range=(1,2), min_df=0.0, remove_stopwords=False)\n",
        "\n",
        "model = SGDClassifier(loss='hinge', max_iter=500)\n",
        "clf = CalibratedClassifierCV(model) \n",
        "model = clf.fit(x_train, y_train)\n",
        "\n",
        "predict = clf.predict(x_test)\n",
        "probab = clf.predict_proba(x_test)\n",
        "\n",
        "print(metrics(y_test, predict, ['Positive', 'Negative']))\n",
        "\n",
        "df= pd.DataFrame({'Id': np.arange(y_test.shape[0]), 'Label': y_test, 'Prediction': predict, 'Probability': probab.tolist()})\n",
        "df.to_csv('/content/drive/My Drive/nlp/probab/SGDC_cv_without_preprocessing.csv')"
      ],
      "metadata": {
        "id": "g5qPAXDZXhY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "_, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "model = LinearSVC()\n",
        "clf = CalibratedClassifierCV(model) \n",
        "model = clf.fit(x_train, y_train)\n",
        "\n",
        "predict = clf.predict(x_test)\n",
        "probab = clf.predict_proba(x_test)\n",
        "\n",
        "print(metrics(y_test, predict, ['Positive', 'Negative']))\n",
        "\n",
        "df= pd.DataFrame({'Id': np.arange(y_test.shape[0]), 'Label': y_test, 'prediction': predict, 'Probability': probab.tolist()})\n",
        "df.to_csv('/content/drive/My Drive/nlp/probab/LinearSVC_tfidf_without_preprocessing.csv')"
      ],
      "metadata": {
        "id": "VIkQp1PfbNKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tuning"
      ],
      "metadata": {
        "id": "lI7DYDs5f6Zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "model = SVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SVC_alone_tfidf_without_preprocessing.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "4Dp40PIqjk6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10, 100], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001],\n",
        "              'kernel': ['linear']}\n",
        " \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "grid.fit(x_train, y_train)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "print(grid.best_estimator_)\n",
        "\n",
        "grid_predictions = grid.predict(x_test)\n",
        "print(classification_report(y_test, grid_predictions))"
      ],
      "metadata": {
        "id": "tTBJGfhpf4ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word2Vec"
      ],
      "metadata": {
        "id": "W1TgFm95ptnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = feature_extraction.create_word2vec_model(x_train['review'], x_test['review'])\n",
        "x_train, x_test = feature_extraction.get_word2vec_embedding(word2vec_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = LinearSVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "b8qgrOhCuIH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "lkw4T3QW40yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GloVe"
      ],
      "metadata": {
        "id": "pbj_JV47Xysh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dirname = os.path.dirname(__file__)\n",
        "filepath = os.path.join(dirname, 'glove.6B.200d.txt')\n",
        "\n",
        "word2vec_output_file = 'glove.6B.200d' + '.word2vec'\n",
        "\n",
        "glove_model = feature_extraction.load_glove_model(filepath, word2vec_output_file)\n",
        "x_train, x_test = feature_extraction.get_glove_embedding(glove_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = LinearSVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "jMN6ERALuXyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "wwmQ-O2f44QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neutral dataset with best models"
      ],
      "metadata": {
        "id": "CVx7K26HA6N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tfidf(x_train, x_test, test, ngram_range = None):\n",
        "    \n",
        "    tfidf = TfidfVectorizer(min_df=0.0002)\n",
        "        \n",
        "    if ngram_range != None:\n",
        "        tfidf.ngram_range = ngram_range\n",
        "        \n",
        "    tfidf.fit(x_train)\n",
        "    x_train_vector = tfidf.transform(x_train)\n",
        "    x_test_vector = tfidf.transform(x_test)\n",
        "    test_vector = tfidf.transform(test)\n",
        "    \n",
        "    return x_train_vector, x_test_vector, test_vector"
      ],
      "metadata": {
        "id": "AsrWAQZs_DQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neutral_df = pd.read_csv('/content/drive/My Drive/nlp/data/neutral_dataset_without_preprocessing.csv', converters = {'Phrase': str})\n",
        "neutral_df.rename(columns = {'Phrase':'review', 'Sentiment':'sentiment'}, inplace = True)\n",
        "\n",
        "x_train, x_test, y_train, y_test = read_files()\n",
        "x_train, x_test, test = get_tfidf(x_train['review'], x_test['review'], neutral_df['review'], ngram_range=(1,2))"
      ],
      "metadata": {
        "id": "2STCt1zf6Jrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression"
      ],
      "metadata": {
        "id": "TnWhAmoWHGyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(C=29.763514416313132, penalty='l2', max_iter=500)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "\n",
        "predict = model.predict(test)\n",
        "probab = model.predict_proba(test)"
      ],
      "metadata": {
        "id": "IcLT4a3BACyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.DataFrame({'Id': neutral_df['SentenceId'].to_numpy(), 'Label': neutral_df['sentiment'], 'Prediction': predict, 'Probability': probab.tolist()})\n",
        "df.to_csv('/content/drive/My Drive/nlp/probab/Neutral_LogisticRegression_tfidf_without_preprocessing_both.csv', index=False)"
      ],
      "metadata": {
        "id": "LHk_Lh8gAzrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_for_neutral(neutral_df['sentiment'], predict, ['1','0'])"
      ],
      "metadata": {
        "id": "i6rXXrpB5ica"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LinearSVC"
      ],
      "metadata": {
        "id": "aqU6jnfLHDeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearSVC()\n",
        "clf = CalibratedClassifierCV(model) \n",
        "model = clf.fit(x_train, y_train)\n",
        "\n",
        "predict = clf.predict(test)\n",
        "probab = clf.predict_proba(test)"
      ],
      "metadata": {
        "id": "3TZksz0pHCtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.DataFrame({'Id': neutral_df['SentenceId'].to_numpy(), 'Label': neutral_df['sentiment'], 'Prediction': predict, 'Probability': probab.tolist()})\n",
        "df.to_csv('/content/drive/My Drive/nlp/probab/Neutral_LinearSVC_tfidf_without_preprocessing_both.csv', index=False)"
      ],
      "metadata": {
        "id": "KtmPXZ85HVNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_for_neutral(neutral_df['sentiment'], predict, ['1','0'])"
      ],
      "metadata": {
        "id": "4msselatHiVi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}