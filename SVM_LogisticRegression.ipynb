{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "y8ErXtTnU6w_",
        "ggFJAgWOVAQc",
        "Osoet2yIq7fg",
        "lI7DYDs5f6Zc",
        "W1TgFm95ptnX",
        "pbj_JV47Xysh",
        "aqU6jnfLHDeD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries and helper functions"
      ],
      "metadata": {
        "id": "zMC8kVG4X_Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/nlp/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYwuT0PCO-r2",
        "outputId": "90a06b6c-3934-4a36-830f-9ee4d9778516"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnHoJRMmXk_7",
        "outputId": "046baf00-4d18-4bbc-871f-87e30de33ef3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.0.0.tar.gz (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.0.0-py3-none-any.whl size=193022 sha256=87bedfbacc210734c28547e66b66350da6e3a6fcc5b3423ca1ef828e96cc51cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/29/4d/3cfe7452ac7d8d83b1930f8a6205c3c9649b24e80f9029fc38\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VQtj5lQW2AZ",
        "outputId": "f34c9a43-51cb-4c92-ea05-9b73152ac089"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "import json\n",
        "from sklearn import metrics as m\n",
        "import numpy as np\n",
        "from os import path\n",
        "import utils\n",
        "from utils import preprocessing\n",
        "from utils import feature_extraction\n",
        "from sklearn.calibration import CalibratedClassifierCV"
      ],
      "metadata": {
        "id": "W93J1WFtUlni"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_files():\n",
        "  x_train = pd.read_csv('/content/drive/My Drive/nlp/data/x_train_without_preprocessing.csv', converters = {'review': str})\n",
        "  x_test = pd.read_csv('/content/drive/My Drive/nlp/data/x_test_without_preprocessing.csv', converters = {'review': str})\n",
        "  y_train = pd.read_csv('/content/drive/My Drive/nlp/data/y_train_without_preprocessing.csv').values.ravel()\n",
        "  y_test = pd.read_csv('/content/drive/My Drive/nlp/data/y_test_without_preprocessing.csv').values.ravel()\n",
        "\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "metadata": {
        "id": "lYT2IDP8U4ww"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def json_metrics(file_name, prediction_model, embedding, metrics, df):\n",
        "    dictionary = {'Model': prediction_model,\n",
        "                  'User embedding': embedding,\n",
        "                  'Metrics': metrics,\n",
        "                  'Data': df.to_dict('records')}\n",
        "\n",
        "    if path.isfile(file_name):  # file exist\n",
        "        with open(file_name) as fp:\n",
        "            listObj = json.load(fp)\n",
        "\n",
        "        listObj.append(dictionary)\n",
        "\n",
        "        with open(file_name, 'w') as json_file:\n",
        "            json.dump(listObj, json_file, indent=4)\n",
        "    else:\n",
        "        with open(file_name, 'w') as json_file:\n",
        "            json.dump([dictionary], json_file, indent=4)\n",
        "\n",
        "\n",
        "def metrics(y_test, y_pred, target_names):\n",
        "    tn, fp, fn, tp = m.confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
        "    dict_confusion = {'True negative': int(tn),\n",
        "                      'False positive': int(fp),\n",
        "                      'False negative': int(fn),\n",
        "                      'True positive': int(tp),\n",
        "                      }\n",
        "    dict_report = m.classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
        "    return {**dict_confusion, **dict_report}\n",
        "\n",
        "def metrics_for_neutral(y_test, y_pred, target_names):\n",
        "  FP = TP = TN = FN = NP = NN = 0\n",
        "\n",
        "  for i in range(len(y_pred)):\n",
        "    prediction = y_pred[i]\n",
        "    true = y_test[i]\n",
        "\n",
        "    if prediction == 1 and (true == 1 or true == 0):\n",
        "      FP += 1\n",
        "    elif prediction == 1 and (true == 3 or true == 4):\n",
        "      TP += 1\n",
        "    elif prediction == 0 and (true == 1 or true == 0) :\n",
        "      TN += 1\n",
        "    elif prediction == 0 and (true == 3 or true == 4):\n",
        "      FN += 1\n",
        "    elif prediction == 1 and true == 2:\n",
        "      NP += 1\n",
        "    elif prediction == 0 and true == 2:\n",
        "      NN += 1\n",
        "      \n",
        "  dict_confusion = {'True negative' : int(TN),\n",
        "        'False positive' : int(FP),\n",
        "        'False negative' : int(FN),\n",
        "        'True positive' : int(TP),\n",
        "        'Neutral positive' : int(NP),\n",
        "        'Neutral negative' : int(NN),\n",
        "        }\n",
        "  return {**dict_confusion}"
      ],
      "metadata": {
        "id": "IDuJZ1EvNMsU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic regression"
      ],
      "metadata": {
        "id": "cq6620aCO_qU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tuning"
      ],
      "metadata": {
        "id": "y8ErXtTnU6w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "logModel = LogisticRegression()\n",
        "param_grid = [    \n",
        "    {'penalty' : ['l1', 'l2'],\n",
        "    'C' : np.logspace(-4, 4, 20),\n",
        "     'solver' : ['lbfgs', 'newton-cg', 'liblinear'],\n",
        "    'max_iter' : [500, 1000]\n",
        "    }\n",
        "]\n",
        "clf = GridSearchCV(logModel, param_grid = param_grid, cv=3, verbose=True)\n",
        "best_clf = clf.fit(x_train, y_train)\n",
        "best_clf.best_estimator_"
      ],
      "metadata": {
        "id": "5JNoeDpcU74u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best accuracy score for the training dataset\n",
        "print(f'The best accuracy score for the training dataset is {best_clf.best_score_:.4f}')\n",
        "\n",
        "# Print the hyperparameters for the best score\n",
        "print(f'The best hyperparameters are {best_clf.best_params_}')\n",
        "\n",
        "# Print the best accuracy score for the testing dataset\n",
        "print(f'The accuracy score for the testing dataset is {best_clf.score(x_test, y_test):.4f}')\n",
        "\n",
        "print(best_clf.best_estimator_.get_params())"
      ],
      "metadata": {
        "id": "G-j3rguPVMGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Best model"
      ],
      "metadata": {
        "id": "vKqZf92oU9e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "#_, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "#COUNT VECTORIZER\n",
        "_, x_train, x_test = feature_extraction.get_count_vector(x_train['review'], x_test['review'], ngram_range=(1,2), min_df=0.0, remove_stopwords=False)\n",
        "\n",
        "model = LogisticRegression(C=29.763514416313132, penalty='l2', max_iter=500)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "\n",
        "predict = model.predict(x_test)\n",
        "probab = model.predict_proba(x_test)\n",
        "\n",
        "metric = metrics(y_test, predict, ['Positive', 'Negative'])\n",
        "json_metrics('/content/drive/My Drive/nlp/json/LR_cv_without_preprocessing_neutral.json', 'LR without preproces neutral', 'cv', metric, pd.DataFrame())\n",
        "\n",
        "df= pd.DataFrame({'Id': np.arange(y_test.shape[0]), 'Label': y_test, 'Prediction': predict, 'Probability': probab.tolist()})\n",
        "df.to_csv('/content/drive/My Drive/nlp/probab/lr_cv_without_preprocessing_neutral.csv')"
      ],
      "metadata": {
        "id": "bxheClsAQEyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word2vec"
      ],
      "metadata": {
        "id": "ggFJAgWOVAQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#WORD2VEC\n",
        "word2vec_model = feature_extraction.create_word2vec_model(x_train['review'], x_test['review']) \n",
        "x_train, x_test = feature_extraction.get_word2vec_embedding(word2vec_model, x_train['review'], x_test['review']) \n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "3cVlUA4QiUxY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "208148cc-9205-42bd-f126-04909607b609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-4fe04564764d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#WORD2VEC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mword2vec_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_word2vec_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word2vec_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/nlp/utils/feature_extraction.py\u001b[0m in \u001b[0;36mcreate_word2vec_model\u001b[0;34m(x_train, x_test)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mnegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# for negative sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# no.of cores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     )\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'vector_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GloVe"
      ],
      "metadata": {
        "id": "Osoet2yIq7fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#GLOVE\n",
        "dirname = os.path.dirname(__file__)\n",
        "filepath = os.path.join(dirname, 'glove.6B.200d.txt')\n",
        "\n",
        "word2vec_output_file = 'glove.6B.200d' + '.word2vec'\n",
        "\n",
        "glove_model = feature_extraction.load_glove_model(filepath, word2vec_output_file)\n",
        "x_train, x_test = feature_extraction.get_glove_embedding(glove_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "pickle.dump(model, open('model_logistic_regression_glove.sav', 'wb')) #save model\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "UfvRyqpUq6eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM"
      ],
      "metadata": {
        "id": "nAKaLlw_UXjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "#dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "#COUNT VECTORIZER\n",
        "_, x_train, x_test = feature_extraction.get_count_vector(x_train['review'], x_test['review'], ngram_range=(1,2), min_df=0.0, remove_stopwords=False)\n",
        "\n",
        "model = SGDClassifier(loss='hinge', max_iter=500)\n",
        "clf = CalibratedClassifierCV(model) \n",
        "model = clf.fit(x_train, y_train)\n",
        "\n",
        "predict = clf.predict(x_test)\n",
        "probab = clf.predict_proba(x_test)\n",
        "\n",
        "metric = metrics(y_test, predict, ['Positive', 'Negative'])\n",
        "json_metrics('/content/drive/My Drive/nlp/json/SGDC_without_preprocessing.json', 'SGDC without preproces', 'cv', metric, pd.DataFrame())\n",
        "\n",
        "df= pd.DataFrame({'Id': np.arange(y_test.shape[0]), 'Label': y_test, 'Prediction': predict, 'Probability': probab.tolist()})\n",
        "df.to_csv('/content/drive/My Drive/nlp/probab/SGDC_cv_without_preprocessing.csv')"
      ],
      "metadata": {
        "id": "g5qPAXDZXhY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "#dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "model = LinearSVC()\n",
        "clf = CalibratedClassifierCV(model) \n",
        "model = clf.fit(x_train, y_train)\n",
        "\n",
        "predict = clf.predict(x_test)\n",
        "probab = clf.predict_proba(x_test)\n",
        "\n",
        "metric = metrics(y_test, predict, ['Positive', 'Negative'])\n",
        "json_metrics('/content/drive/My Drive/nlp/json/LinearSVC_without_preprocessing.json', 'LinearSVC without preproces', 'TFIDF', metric, pd.DataFrame())\n",
        "\n",
        "df= pd.DataFrame({'Id': np.arange(y_test.shape[0]), 'Label': y_test, 'prediction': predict, 'Probability': probab.tolist()})\n",
        "df.to_csv('/content/drive/My Drive/nlp/probab/LinearSVC_tfidf_without_preprocessing.csv')"
      ],
      "metadata": {
        "id": "VIkQp1PfbNKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tuning"
      ],
      "metadata": {
        "id": "lI7DYDs5f6Zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "model = SVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SVC_alone_tfidf_without_preprocessing.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "4Dp40PIqjk6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10, 100], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001],\n",
        "              'kernel': ['linear']}\n",
        " \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "grid.fit(x_train, y_train)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "print(grid.best_estimator_)\n",
        "\n",
        "grid_predictions = grid.predict(x_test)\n",
        "print(classification_report(y_test, grid_predictions))"
      ],
      "metadata": {
        "id": "tTBJGfhpf4ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word2Vec"
      ],
      "metadata": {
        "id": "W1TgFm95ptnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = feature_extraction.create_word2vec_model(x_train['review'], x_test['review'])\n",
        "x_train, x_test = feature_extraction.get_word2vec_embedding(word2vec_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = LinearSVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SVC_word2vec.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "b8qgrOhCuIH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SGD_word2vec.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "lkw4T3QW40yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GloVe"
      ],
      "metadata": {
        "id": "pbj_JV47Xysh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dirname = os.path.dirname(__file__)\n",
        "filepath = os.path.join(dirname, 'glove.6B.200d.txt')\n",
        "\n",
        "word2vec_output_file = 'glove.6B.200d' + '.word2vec'\n",
        "\n",
        "glove_model = feature_extraction.load_glove_model(filepath, word2vec_output_file)\n",
        "x_train, x_test = feature_extraction.get_glove_embedding(glove_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = LinearSVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SVC_glove.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "jMN6ERALuXyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SGD_glove.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "wwmQ-O2f44QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neutral dataset with best models"
      ],
      "metadata": {
        "id": "CVx7K26HA6N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tfidf(x_train, x_test, test, ngram_range = None):\n",
        "    \n",
        "    tfidf = TfidfVectorizer(min_df=0.0002)\n",
        "        \n",
        "    if ngram_range != None:\n",
        "        tfidf.ngram_range = ngram_range\n",
        "        \n",
        "    tfidf.fit(x_train)\n",
        "    x_train_vector = tfidf.transform(x_train)\n",
        "    x_test_vector = tfidf.transform(x_test)\n",
        "    test_vector = tfidf.transform(test)\n",
        "    \n",
        "    return x_train_vector, x_test_vector, test_vector"
      ],
      "metadata": {
        "id": "AsrWAQZs_DQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neutral_df = pd.read_csv('/content/drive/My Drive/nlp/data/neutral_dataset_without_preprocessing.csv', converters = {'Phrase': str})\n",
        "neutral_df.rename(columns = {'Phrase':'review', 'Sentiment':'sentiment'}, inplace = True)\n",
        "\n",
        "x_train, x_test, y_train, y_test = read_files()\n",
        "x_train, x_test, test = get_tfidf(x_train['review'], x_test['review'], neutral_df['review'], ngram_range=(1,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2STCt1zf6Jrs",
        "outputId": "994cf64a-3441-4545-d53d-c8a6a2156b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<8529x136888 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 197346 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression"
      ],
      "metadata": {
        "id": "TnWhAmoWHGyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(C=29.763514416313132, penalty='l2', max_iter=500)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "\n",
        "predict = model.predict(test)\n",
        "probab = model.predict_proba(test)"
      ],
      "metadata": {
        "id": "IcLT4a3BACyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.DataFrame({'Id': neutral_df['SentenceId'].to_numpy(), 'Label': neutral_df['sentiment'], 'Prediction': predict, 'Probability': probab.tolist()})\n",
        "df.to_csv('/content/drive/My Drive/nlp/probab/Neutral_LogisticRegression_tfidf_without_preprocessing_both.csv', index=False)"
      ],
      "metadata": {
        "id": "LHk_Lh8gAzrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_for_neutral(neutral_df['sentiment'], predict, ['1','0'])"
      ],
      "metadata": {
        "id": "i6rXXrpB5ica",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec518111-edca-4b5b-e11b-8410926715df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'False negative': 738,\n",
              " 'False positive': 803,\n",
              " 'Neutral negative': 872,\n",
              " 'Neutral positive': 783,\n",
              " 'True negative': 2469,\n",
              " 'True positive': 2864}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LinearSVC"
      ],
      "metadata": {
        "id": "aqU6jnfLHDeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearSVC()\n",
        "clf = CalibratedClassifierCV(model) \n",
        "model = clf.fit(x_train, y_train)\n",
        "\n",
        "predict = clf.predict(test)\n",
        "probab = clf.predict_proba(test)"
      ],
      "metadata": {
        "id": "3TZksz0pHCtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.DataFrame({'Id': neutral_df['SentenceId'].to_numpy(), 'Label': neutral_df['sentiment'], 'Prediction': predict, 'Probability': probab.tolist()})\n",
        "df.to_csv('/content/drive/My Drive/nlp/probab/Neutral_LinearSVC_tfidf_without_preprocessing_both.csv', index=False)"
      ],
      "metadata": {
        "id": "KtmPXZ85HVNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_for_neutral(neutral_df['sentiment'], predict, ['1','0'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4msselatHiVi",
        "outputId": "c98673d4-355f-4fdb-9f65-5dad41a7998e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'False negative': 744,\n",
              " 'False positive': 783,\n",
              " 'Neutral negative': 879,\n",
              " 'Neutral positive': 776,\n",
              " 'True negative': 2489,\n",
              " 'True positive': 2858}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}