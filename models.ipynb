{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/nlp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYwuT0PCO-r2",
        "outputId": "84e10bee-6593-44f3-e94d-9368856f2e6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic regression"
      ],
      "metadata": {
        "id": "cq6620aCO_qU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "x_train = pd.read_csv('x_train.csv', converters = {'review': str})\n",
        "x_train = x_train['review'].values\n",
        "x_test = pd.read_csv('x_test.csv', converters = {'review': str})\n",
        "x_test = x_test['review'].values\n",
        "y_train = pd.read_csv('y_train.csv').values.ravel()\n",
        "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
        "\n",
        "tfidf = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2), sublinear_tf=True)\n",
        "x_train = tfidf.fit_transform(x_train)\n",
        "x_test = tfidf.transform(x_test)\n",
        "\n",
        "lr = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = lr.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "lr_predict = lr.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ-3Tzy4QARU",
        "outputId": "a7bc2825-c582-4b74-abb7-34db4669480f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1, max_iter=500, random_state=123)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.88      0.89      3824\n",
            "    Negative       0.88      0.91      0.89      3676\n",
            "\n",
            "    accuracy                           0.89      7500\n",
            "   macro avg       0.89      0.89      0.89      7500\n",
            "weighted avg       0.89      0.89      0.89      7500\n",
            "\n",
            "[[3352  324]\n",
            " [ 471 3353]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "x_train = pd.read_csv('x_train.csv', converters = {'review': str})\n",
        "x_train = x_train['review'].values\n",
        "x_test = pd.read_csv('x_test.csv', converters = {'review': str})\n",
        "x_test = x_test['review'].values\n",
        "y_train = pd.read_csv('y_train.csv').values.ravel()\n",
        "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
        "\n",
        "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
        "x_train = cv.fit_transform(x_train)\n",
        "x_test = cv.transform(x_test)\n",
        "\n",
        "lr = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = lr.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "lr_predict = lr.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxheClsAQEyB",
        "outputId": "709ba58e-8314-448e-be80-3659b9d0aa23"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1, max_iter=500, random_state=123)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.89      0.90      3824\n",
            "    Negative       0.89      0.91      0.90      3676\n",
            "\n",
            "    accuracy                           0.90      7500\n",
            "   macro avg       0.90      0.90      0.90      7500\n",
            "weighted avg       0.90      0.90      0.90      7500\n",
            "\n",
            "[[3357  319]\n",
            " [ 416 3408]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM"
      ],
      "metadata": {
        "id": "nAKaLlw_UXjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "x_train = pd.read_csv('x_train.csv', converters = {'review': str})\n",
        "x_train = x_train['review'].values\n",
        "x_test = pd.read_csv('x_test.csv', converters = {'review': str})\n",
        "x_test = x_test['review'].values\n",
        "y_train = pd.read_csv('y_train.csv').values.ravel()\n",
        "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
        "\n",
        "tfidf = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2), sublinear_tf=True)\n",
        "x_train = tfidf.fit_transform(x_train)\n",
        "x_test = tfidf.transform(x_test)\n",
        "\n",
        "svm = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = svm.fit(x_train, y_train)\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5qPAXDZXhY6",
        "outputId": "eddf9961-046c-4de6-95c1-2fffc1e00c13"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.87      0.89      3824\n",
            "    Negative       0.87      0.92      0.89      3676\n",
            "\n",
            "    accuracy                           0.89      7500\n",
            "   macro avg       0.89      0.89      0.89      7500\n",
            "weighted avg       0.89      0.89      0.89      7500\n",
            "\n",
            "[[3367  309]\n",
            " [ 498 3326]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "x_train = pd.read_csv('x_train.csv', converters = {'review': str})\n",
        "x_train = x_train['review'].values\n",
        "x_test = pd.read_csv('x_test.csv', converters = {'review': str})\n",
        "x_test = x_test['review'].values\n",
        "y_train = pd.read_csv('y_train.csv').values.ravel()\n",
        "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
        "\n",
        "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
        "x_train = cv.fit_transform(x_train)\n",
        "x_test = cv.transform(x_test)\n",
        "\n",
        "svm = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = svm.fit(x_train, y_train)\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La59TWb0ZPQI",
        "outputId": "83fc278a-3954-4c79-ddf7-d6c4b62b4054"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.90      0.90      3824\n",
            "    Negative       0.89      0.91      0.90      3676\n",
            "\n",
            "    accuracy                           0.90      7500\n",
            "   macro avg       0.90      0.90      0.90      7500\n",
            "weighted avg       0.90      0.90      0.90      7500\n",
            "\n",
            "[[3331  345]\n",
            " [ 400 3424]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "x_train = pd.read_csv('x_train.csv', converters = {'review': str})\n",
        "x_train = x_train['review'].values\n",
        "x_test = pd.read_csv('x_test.csv', converters = {'review': str})\n",
        "x_test = x_test['review'].values\n",
        "y_train = pd.read_csv('y_train.csv').values.ravel()\n",
        "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
        "\n",
        "tfidf = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2), sublinear_tf=True)\n",
        "x_train = tfidf.fit_transform(x_train)\n",
        "x_test = tfidf.transform(x_test)\n",
        "\n",
        "svm = svm.LinearSVC()\n",
        "svm_predict = svm.fit(x_train, y_train).predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIkQp1PfbNKu",
        "outputId": "b8ce1bbd-5f35-4b82-8991-888379ff8ae4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.93      0.90      0.91      3824\n",
            "    Negative       0.90      0.93      0.91      3676\n",
            "\n",
            "    accuracy                           0.91      7500\n",
            "   macro avg       0.91      0.91      0.91      7500\n",
            "weighted avg       0.91      0.91      0.91      7500\n",
            "\n",
            "[[3420  256]\n",
            " [ 399 3425]]\n"
          ]
        }
      ]
    }
  ]
}