{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/nlp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYwuT0PCO-r2",
        "outputId": "c01b1eea-92e7-4c80-fc4f-0bcefe0e1841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnHoJRMmXk_7",
        "outputId": "abc64cf3-71f3-4434-ad2f-56b70c2934c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 5.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=75e157c59e1b1123f2d8e2a6c355e5a14405932a47878daf24e398db85f24aa5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import utils\n",
        "from utils import preprocessing\n",
        "from utils import feature_extraction"
      ],
      "metadata": {
        "id": "W93J1WFtUlni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_files():\n",
        "  x_train = pd.read_csv('x_train.csv', converters = {'review': str})\n",
        "  #x_train = x_train['review'].values\n",
        "  x_test = pd.read_csv('x_test.csv', converters = {'review': str})\n",
        "  #x_test = x_test['review'].values\n",
        "  y_train = pd.read_csv('y_train.csv').values.ravel()\n",
        "  y_test = pd.read_csv('y_test.csv').values.ravel()\n",
        "\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "metadata": {
        "id": "lYT2IDP8U4ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic regression"
      ],
      "metadata": {
        "id": "cq6620aCO_qU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "pickle.dump(model, open('model_logistic_regression_tfidf.sav', 'wb'))\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxheClsAQEyB",
        "outputId": "b96aafef-877e-4a94-f526-5511f5102817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1, max_iter=500, random_state=123)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.92      0.88      0.90      3824\n",
            "    Negative       0.88      0.92      0.90      3676\n",
            "\n",
            "    accuracy                           0.90      7500\n",
            "   macro avg       0.90      0.90      0.90      7500\n",
            "weighted avg       0.90      0.90      0.90      7500\n",
            "\n",
            "[[3381  295]\n",
            " [ 440 3384]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loaded_model = pickle.load(open('model_logistic_regression_tfidf.sav', 'rb'))\n",
        "#result = loaded_model.score(x_test, y_test)\n",
        "#print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOgKcNEAXu5A",
        "outputId": "f82552a7-2572-4fcd-84a6-6927ac310972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8845333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#COUNT VECTORIZER\n",
        "_, x_train, x_test = feature_extraction.get_count_vector(x_train['review'], x_test['review'], ngram_range=(1,2), min_df=0.0, remove_stopwords=False)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "pickle.dump(model, open('model_logistic_regression_cv.sav', 'wb')) #save model\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ-3Tzy4QARU",
        "outputId": "453fe021-701b-459c-aa05-70a11c74a032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1, max_iter=500, random_state=123)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.89      0.90      3824\n",
            "    Negative       0.89      0.91      0.90      3676\n",
            "\n",
            "    accuracy                           0.90      7500\n",
            "   macro avg       0.90      0.90      0.90      7500\n",
            "weighted avg       0.90      0.90      0.90      7500\n",
            "\n",
            "[[3357  319]\n",
            " [ 416 3408]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#WORD2VEC\n",
        "word2vec_model = feature_extraction.create_word2vec_model(x_train['review'], x_test['review']) \n",
        "x_train, x_test = feature_extraction.get_word2vec_embedding(word2vec_model, x_train['review'], x_test['review']) \n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "pickle.dump(model, open('model_logistic_regression_word2vec.sav', 'wb')) #save model\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "3cVlUA4QiUxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#GLOVE\n",
        "dirname = os.path.dirname(__file__)\n",
        "filepath = os.path.join(dirname, 'glove.6B.200d.txt')\n",
        "\n",
        "word2vec_output_file = 'glove.6B.200d' + '.word2vec'\n",
        "\n",
        "glove_model = feature_extraction.load_glove_model(filepath, word2vec_output_file)\n",
        "x_train, x_test = feature_extraction.get_glove_embedding(glove_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "pickle.dump(model, open('model_logistic_regression_glove.sav', 'wb')) #save model\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "Wc1QsKbct-LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM"
      ],
      "metadata": {
        "id": "nAKaLlw_UXjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SGD_tfidf.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5qPAXDZXhY6",
        "outputId": "9d54a4bb-5e75-433b-aa1d-a111215d121d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.92      0.88      0.90      3824\n",
            "    Negative       0.88      0.93      0.90      3676\n",
            "\n",
            "    accuracy                           0.90      7500\n",
            "   macro avg       0.90      0.90      0.90      7500\n",
            "weighted avg       0.90      0.90      0.90      7500\n",
            "\n",
            "[[3401  275]\n",
            " [ 471 3353]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#COUNT VECTORIZER\n",
        "_, x_train, x_test = feature_extraction.get_count_vector(x_train['review'], x_test['review'], ngram_range=(1,2), min_df=0.0, remove_stopwords=False)\n",
        "\n",
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SGD_cv.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La59TWb0ZPQI",
        "outputId": "9052a792-fd03-4f10-fa07-7e9c9d0bd35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.90      0.90      3824\n",
            "    Negative       0.89      0.91      0.90      3676\n",
            "\n",
            "    accuracy                           0.90      7500\n",
            "   macro avg       0.90      0.90      0.90      7500\n",
            "weighted avg       0.90      0.90      0.90      7500\n",
            "\n",
            "[[3331  345]\n",
            " [ 400 3424]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "model = svm.LinearSVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SVC_tfidf.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIkQp1PfbNKu",
        "outputId": "bebf3b14-4160-4d3d-9349-97e628b2c374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.92      0.90      0.91      3824\n",
            "    Negative       0.90      0.92      0.91      3676\n",
            "\n",
            "    accuracy                           0.91      7500\n",
            "   macro avg       0.91      0.91      0.91      7500\n",
            "weighted avg       0.91      0.91      0.91      7500\n",
            "\n",
            "[[3366  310]\n",
            " [ 387 3437]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = feature_extraction.create_word2vec_model(x_train['review'], x_test['review'])\n",
        "x_train, x_test = feature_extraction.get_word2vec_embedding(word2vec_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = svm.LinearSVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SVC_word2vec.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "b8qgrOhCuIH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SGD_word2vec.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "lkw4T3QW40yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirname = os.path.dirname(__file__)\n",
        "filepath = os.path.join(dirname, 'glove.6B.200d.txt')\n",
        "\n",
        "word2vec_output_file = 'glove.6B.200d' + '.word2vec'\n",
        "\n",
        "glove_model = feature_extraction.load_glove_model(filepath, word2vec_output_file)\n",
        "x_train, x_test = feature_extraction.get_glove_embedding(glove_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = svm.LinearSVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SVC_glove.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "jMN6ERALuXyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SGD_glove.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "wwmQ-O2f44QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MLP Classifier"
      ],
      "metadata": {
        "id": "bA3JcwFO_n5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "nlp_lg = spacy.load('en_core_web_lg')\n",
        "\n",
        "x_train = pd.read_csv('x_train.csv', converters = {'review': str})\n",
        "x_train = x_train['review'].values\n",
        "x_test = pd.read_csv('x_test.csv', converters = {'review': str})\n",
        "x_test = x_test['review'].values\n",
        "y_train = pd.read_csv('y_train.csv').values.ravel()\n",
        "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
        "\n",
        "#converting the data to a vector representation\n",
        "def convert_data(corpus):\n",
        "    new_corpus = []\n",
        "    for document in corpus:\n",
        "        doc = nlp_lg(document)\n",
        "        new_corpus.append(doc.vector)\n",
        "    return(new_corpus)\n",
        "\n",
        "\n",
        "x_train = convert_data(x_train)\n",
        "x_test = convert_data(x_test)\n",
        "\n",
        "#MLP classifier \n",
        "classifier = MLPClassifier(hidden_layer_sizes=(300,150,50), max_iter=300, activation = 'relu',solver='adam',random_state=1)\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "#creating the confusion matrix\n",
        "cm = confusion_matrix(y_pred, y_test)\n",
        "diagonal_sum = cm.trace()\n",
        "sum_of_all_elements = cm.sum()\n",
        "accuracy = diagonal_sum / sum_of_all_elements\n",
        "\n",
        "#printing the results of MLP\n",
        "print(\"MLPClassifier accuracy: \", accuracy)\n",
        "print(\"\\nConfusion matrix: \\n\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "5fQ_HD7D_pe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(y_test, y_pred, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "Uogtg3Yx_os-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}