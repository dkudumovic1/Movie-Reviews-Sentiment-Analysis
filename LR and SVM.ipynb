{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYwuT0PCO-r2",
        "outputId": "c01b1eea-92e7-4c80-fc4f-0bcefe0e1841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/nlp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnHoJRMmXk_7",
        "outputId": "abc64cf3-71f3-4434-ad2f-56b70c2934c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 5.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=75e157c59e1b1123f2d8e2a6c355e5a14405932a47878daf24e398db85f24aa5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W93J1WFtUlni"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import utils\n",
        "from utils import preprocessing\n",
        "from utils import feature_extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYT2IDP8U4ww"
      },
      "outputs": [],
      "source": [
        "def read_files():\n",
        "  x_train = pd.read_csv('x_train.csv', converters = {'review': str})\n",
        "  #x_train = x_train['review'].values\n",
        "  x_test = pd.read_csv('x_test.csv', converters = {'review': str})\n",
        "  #x_test = x_test['review'].values\n",
        "  y_train = pd.read_csv('y_train.csv').values.ravel()\n",
        "  y_test = pd.read_csv('y_test.csv').values.ravel()\n",
        "\n",
        "  return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq6620aCO_qU"
      },
      "source": [
        "#Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxheClsAQEyB",
        "outputId": "b96aafef-877e-4a94-f526-5511f5102817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1, max_iter=500, random_state=123)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.92      0.88      0.90      3824\n",
            "    Negative       0.88      0.92      0.90      3676\n",
            "\n",
            "    accuracy                           0.90      7500\n",
            "   macro avg       0.90      0.90      0.90      7500\n",
            "weighted avg       0.90      0.90      0.90      7500\n",
            "\n",
            "[[3381  295]\n",
            " [ 440 3384]]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "pickle.dump(model, open('model_logistic_regression_tfidf.sav', 'wb'))\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOgKcNEAXu5A",
        "outputId": "f82552a7-2572-4fcd-84a6-6927ac310972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8845333333333333\n"
          ]
        }
      ],
      "source": [
        "#loaded_model = pickle.load(open('model_logistic_regression_tfidf.sav', 'rb'))\n",
        "#result = loaded_model.score(x_test, y_test)\n",
        "#print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ-3Tzy4QARU",
        "outputId": "453fe021-701b-459c-aa05-70a11c74a032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1, max_iter=500, random_state=123)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.89      0.90      3824\n",
            "    Negative       0.89      0.91      0.90      3676\n",
            "\n",
            "    accuracy                           0.90      7500\n",
            "   macro avg       0.90      0.90      0.90      7500\n",
            "weighted avg       0.90      0.90      0.90      7500\n",
            "\n",
            "[[3357  319]\n",
            " [ 416 3408]]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#COUNT VECTORIZER\n",
        "_, x_train, x_test = feature_extraction.get_count_vector(x_train['review'], x_test['review'], ngram_range=(1,2), min_df=0.0, remove_stopwords=False)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "pickle.dump(model, open('model_logistic_regression_cv.sav', 'wb')) #save model\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cVlUA4QiUxY"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#WORD2VEC\n",
        "word2vec_model = feature_extraction.create_word2vec_model(x_train['review'], x_test['review']) \n",
        "x_train, x_test = feature_extraction.get_word2vec_embedding(word2vec_model, x_train['review'], x_test['review']) \n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "pickle.dump(model, open('model_logistic_regression_word2vec.sav', 'wb')) #save model\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc1QsKbct-LE"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#GLOVE\n",
        "dirname = os.path.dirname(__file__)\n",
        "filepath = os.path.join(dirname, 'glove.6B.200d.txt')\n",
        "\n",
        "word2vec_output_file = 'glove.6B.200d' + '.word2vec'\n",
        "\n",
        "glove_model = feature_extraction.load_glove_model(filepath, word2vec_output_file)\n",
        "x_train, x_test = feature_extraction.get_glove_embedding(glove_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=123)\n",
        "lr_fit = model.fit(x_train, y_train)\n",
        "print(lr_fit)\n",
        "\n",
        "pickle.dump(model, open('model_logistic_regression_glove.sav', 'wb')) #save model\n",
        "\n",
        "lr_predict = model.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, lr_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, lr_predict, labels=[1,0])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAKaLlw_UXjn"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5qPAXDZXhY6",
        "outputId": "9d54a4bb-5e75-433b-aa1d-a111215d121d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.92      0.88      0.90      3824\n",
            "    Negative       0.88      0.93      0.90      3676\n",
            "\n",
            "    accuracy                           0.90      7500\n",
            "   macro avg       0.90      0.90      0.90      7500\n",
            "weighted avg       0.90      0.90      0.90      7500\n",
            "\n",
            "[[3401  275]\n",
            " [ 471 3353]]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SGD_tfidf.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La59TWb0ZPQI",
        "outputId": "9052a792-fd03-4f10-fa07-7e9c9d0bd35b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.91      0.90      0.90      3824\n",
            "    Negative       0.89      0.91      0.90      3676\n",
            "\n",
            "    accuracy                           0.90      7500\n",
            "   macro avg       0.90      0.90      0.90      7500\n",
            "weighted avg       0.90      0.90      0.90      7500\n",
            "\n",
            "[[3331  345]\n",
            " [ 400 3424]]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#COUNT VECTORIZER\n",
        "_, x_train, x_test = feature_extraction.get_count_vector(x_train['review'], x_test['review'], ngram_range=(1,2), min_df=0.0, remove_stopwords=False)\n",
        "\n",
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SGD_cv.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIkQp1PfbNKu",
        "outputId": "bebf3b14-4160-4d3d-9349-97e628b2c374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.92      0.90      0.91      3824\n",
            "    Negative       0.90      0.92      0.91      3676\n",
            "\n",
            "    accuracy                           0.91      7500\n",
            "   macro avg       0.91      0.91      0.91      7500\n",
            "weighted avg       0.91      0.91      0.91      7500\n",
            "\n",
            "[[3366  310]\n",
            " [ 387 3437]]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = read_files()\n",
        "\n",
        "#TFIDF\n",
        "dictionary, x_train, x_test = feature_extraction.get_tfidf_vector(x_train['review'], x_test['review'], remove_stopwords=False, ngram_range=(1,2))\n",
        "\n",
        "model = svm.LinearSVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SVC_tfidf.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8qgrOhCuIH1"
      },
      "outputs": [],
      "source": [
        "word2vec_model = feature_extraction.create_word2vec_model(x_train['review'], x_test['review'])\n",
        "x_train, x_test = feature_extraction.get_word2vec_embedding(word2vec_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = svm.LinearSVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SVC_word2vec.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkw4T3QW40yH"
      },
      "outputs": [],
      "source": [
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SGD_word2vec.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMN6ERALuXyJ"
      },
      "outputs": [],
      "source": [
        "dirname = os.path.dirname(__file__)\n",
        "filepath = os.path.join(dirname, 'glove.6B.200d.txt')\n",
        "\n",
        "word2vec_output_file = 'glove.6B.200d' + '.word2vec'\n",
        "\n",
        "glove_model = feature_extraction.load_glove_model(filepath, word2vec_output_file)\n",
        "x_train, x_test = feature_extraction.get_glove_embedding(glove_model, x_train['review'], x_test['review'])\n",
        "\n",
        "model = svm.LinearSVC()\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SVC_glove.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwmQ-O2f44QG"
      },
      "outputs": [],
      "source": [
        "model = SGDClassifier(loss='hinge', max_iter=500, random_state=123)\n",
        "svm = model.fit(x_train, y_train)\n",
        "\n",
        "pickle.dump(model, open('model_svm_SGD_glove.sav', 'wb'))\n",
        "\n",
        "svm_predict = svm.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, svm_predict, target_names=['Positive', 'Negative'])\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_test, svm_predict, labels=[1,0])\n",
        "print(cm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "46289f3f92f675f6c09686056f73d270c3b72d1eca518fe634a57cad5b09cc16"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
